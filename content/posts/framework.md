---
date: '2025-08-26T16:10:39+08:00'
draft: false
title: '大模型架构'
categories: ["大语言模型", "人工智能"]
tags: ["LLM", "价值驱动", "多模态","延迟询问"]
---





# 1) 总体闭环（Control Loop）

```
Perception (多模态输入)
   ↓
Fusion (对齐+融合)
   ↓
Cognition Core (价值驱动的世界模型/规划/不确定性评估)
   ↔ Retrieval Orchestrator (向“库”发多跳检索+工具使用)
   ↓
Decision: {直接输出 | 继续检索 | 询问 (人/代理/工具) | 延迟并学习}
   ↓
Actuators (多模态输出: 文本/语音/图像/图表/代码/动作)
   ↓
Write-back (把新知识/反馈写回“库”，更新价值函数与策略)
```

# 2) 多模态输入：更“像人”的感知层

* 通道与编码器
  文字：Tokenizer/语义编码（LLM/Transformer）。
  语音：ASR（流式更好）+ 说话人分离；保留时序对齐。
  图片/视频：VLM 编码（区域特征、对象检测、OCR 文本抽取）。
  桌面/传感器/日志：结构化解析为事件流（time, source, entities）。
* 对齐与融合
  早期融合（共享编码器）+ 晚期融合（跨模态注意力）；统一到“事件-实体-关系”的中间语义图（见§4 的库设计）。
* 流式/增量
  支持 streaming：边输入边推理（对长语音/视频尤其关键），将“可用片段”优先交给认知层评估。

# 3) 认知（价值驱动，而非相似度驱动）

核心是从“检索相似文本”升级到“在价值函数下决策”。

**3.1 价值函数 U(s, a)**

* 维度：正确性、完整性、时效性、成本/延迟、风险（安全/合规）、用户偏好（语气、格式）、可执行性。
* 个性化：从交互反馈/偏好学习（RLAIF/DPO/对比学习）得到用户特定的权重。

**3.2 世界模型 + 规划器**

* 世界模型（可由 LLM 提示化或 LoRA 细化）：生成“假设 → 推演 → 证据需求”。
* 规划：ReAct/ToT 风格的“推理-工具-证据”循环，但每一步都以 U 的增益为准则，而不是单纯余弦相似度。
* 不确定性估计：口径一致的置信度（对齐生成概率/对比多个样本/校准 ECE），作为是否“继续检索/询问”的阈值信号。

# 4) “库”的编排（Memory + Tools）

把“库”做成分层的**长期记忆系统**，不是一个平铺的向量库：

**4.1 记忆分层**

* 工作记忆（WM）：当前会话与最近上下文（窗口管理/摘要器）。
* 情节记忆（Episodic）：按任务/日期的交互和经历（带时间戳与结果）。
* 语义记忆（Semantic）：文档/网页/论文，切片+多索引（dense/sparse/关键词/结构化字段）。
* 程序化记忆（Procedural）：可调用工具与 API 的“用法卡”（输入/输出模式、前置条件、开销）。
* 知识图谱（KG）：实体-关系-事件三元组（从文本/表格/网页抽取写入），支持多跳查询与溯源。

**4.2 索引与检索**

* **混合检索**：稀疏（BM25/关键词）+ 稠密（向量）+ KG 路径 + 元数据（时间/来源/可信度）。
* **多跳**：先找关键实体与缺口，再指向二级材料（“证据链”）。
* **版本与溯源**：每条证据带来源、时间、版本，输出时自动给“来源-时间”卡片。
* **遗忘/衰减**：对过时材料施加时间衰减，防止旧知识主导。

# 5) “延迟-询问”模块（Ask-or-Wait Policy）

目标：当当前证据不够时，“是否等待并询问/继续检索”的**可计算决策**。

**5.1 决策准则：期望信息价值（EVI）**

* 设当前答案的期望效用 $E[U|\neg ask]$，若发起询问（或更多检索）后的期望效用 $E[U|ask]$；
* 若 $E[U|ask] - E[U|\neg ask] > C_{ask}$（询问成本/等待时间/打扰成本），则触发询问或延迟。
* 估计方法：用不确定性（熵/置信区间）、历史提升（过去相似场景“多问一次”的收益分布）、以及对象可信度当先验。

**5.2 问谁？优先级路由**

1. **工具/数据库**（最低打扰，最快）：内部文档、网页检索、计算/代码执行。
2. **专用代理**：OCR/表格解析/编程执行代理；或“领域专家模型”（金融/医学等）做二次判读。
3. **人类对象**：

   * 用户本人（澄清需求/约束）；
   * 用户指定的协作者列表（项目 Owner/导师/法务）；
   * 众包通道（若允许）。

> 选择策略 = 可靠性 × 响应时延 × 成本 × 隐私级别 × 语境匹配度。

**5.3 询问生成**

* 明确“信息缺口 → 最小化提问”：一次问尽关键变量；
* 输出多选/标注式卡片，降低认知负荷；
* 给出当前已知与待确认项，保证可追溯。

**5.4 伪代码（简化）**

```python
while True:
    x = perceive()                    # 多模态输入
    z = fuse(x)
    plan, conf = reason(z, memory)    # 价值驱动推理+置信度
    if conf >= τ_conf and cost <= τ_cost:
        return act(plan)              # 多模态输出
    gain = estimate_EVI(z, plan, memory)
    if gain > ask_cost:
        target = route_target(z, plan, memory)  # 工具/代理/人
        info = query(target)
        write_back(memory, info)
    else:
        extra = retrieve(memory, plan) # 更深入/多跳检索
        if not extra:
            relax_requirements_or_abort()
```

# 6) 多模态输出（不只文本）

* **文本**：带“证据卡”与“可执行块”（命令/代码/SQL/脚本）。
* **语音**：TTS（情感/语速/场景模板），对可听场景直接播报。
* **图像/图表**：自动生成流程图、架构图、对比表、指标曲线；UI 里可下载。
* **视频/演示**：从要点+配音+字幕合成短讲解。
* **动作**：调用 API/自动化（发日程、建工单、跑脚本），并生成可撤回日志。
* **格式选择器**：依据任务与用户偏好（论文→LaTeX、报告→PPT、开发→Markdown+代码、科普→图解）。

# 7) 训练与对齐（让“价值驱动”真正生效）

* **偏好学习**：RLAIF/DPO，目标是最大化 U，而非困在词面相似度。
* **工具使用微调**：收集“推理-调用-证据-回答”的轨迹，监督/策略梯度联合。
* **不确定性校准**：温度缩放、对比解码、委员会采样，优化 ECE/Brier。
* **多模态联合**：语音-文本对齐、图文问答、视频描述，训练“事件-实体”抽取与对齐器。
* **少样本/连续学习**：把用户场景沉淀为任务卡与单测数据，持续蒸馏到小模型边端（隐私场景）。

# 8) 评测指标（按模块分解 + 端到端）

* 感知：ASR WER、OCR CER、VQA/Caption 指标；
* 检索：nDCG/MRR、证据可解释性打分（溯源覆盖率、时效性）；
* 认知：

  * 任务成功率（Exact/Pass\@k）、步骤最优性（与专家规划对比）、
  * 校准度（ECE、Brier）、反事实鲁棒（扰动后答案稳定性）；
* 询问策略：平均询问次数、用户打扰率、单位提问带来成功率提升（ΔSuccess/Ask）；
* 输出：TTS 主观 MOS、图表正确性（自动单测/审计器）、可执行块成功率；
* 端到端：ROI（成功率 × 质量 / 成本·时延）、用户满意度/复用率。

# 9) 工程落地建议（可替换为你现有栈）

* **编排**：Python Orchestrator（Lang\* 或自建），有清晰的 ToolSpec/MemorySpec。
* **感知**：ASR（流式）、图像/视频 VLM、公式/表格 OCR；
* **检索**：向量库（FAISS/Milvus）+ 关键词（Elasticsearch）+ KG（Neo4j）；
* **模型**：文本 LLM + VLM（可分体），小助手模型做专长工具（表格/代码/图表）；
* **校准与策略**：不确定性估计组件 + EVI 询问策略；
* **合规**：敏感域走本地优先，分级加密；人类在环明确“可被打扰清单”。

# 10) 一个微型示例（你可以把它映射到 ABSA 或通用助理）

**场景**：用户说“把这段会议录音里的决策点做成两页 PPT，并拉出相关论文 3 篇”。

1. 感知：ASR→时间戳→命名实体/议题抽取；
2. 认知：识别“交付物=PPT 两页”“需要外部论文”；
3. 检索：库中找以往模板 + 外部检索论文；
4. 评估：对论文主题置信度低且时间预算足够→触发询问：“更偏工程/学术？近 2 年还是不限？”（多选卡）；
5. 输出：生成两页 PPT（要点、图表），并附论文卡片（标题/年份/一行摘要/链接）；
6. 写回：把最终版本与用户偏好写回“情节/语义记忆”。

---
